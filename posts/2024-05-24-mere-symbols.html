<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0" />
        <title>Travis Athougies - Mere Symbols</title>
        <link rel="stylesheet" type="text/css" href="../css/default.css" />
        <link rel="stylesheet" type="text/css" href="../css/syntax.css" />
        <link rel="stylesheet" type="text/css" href="../css/jquery.modal.css" />
        <link href="http://fonts.googleapis.com/css?family=Open+Sans:400,300,800,700" rel="stylesheet" type="text/css">
        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/javascript" src="../js/jquery.min.js"></script>
        <script type"text javascript" src="../js/jquery.modal.min.js"></script>
	<script type="text/javascript" src="../js/isotope.min.js"></script>
	<script type="text/javascript" src="../js/imagesloaded.min.js"></script>
        <script type="text/javascript" src="../js/gallery.js"></script>
    </head>
    <body>
        <div id="mini-header-bar">
          <div id="show-header">
            ☰
          </div>
          <h1 id="mini-logo">
            <a href="../"><p class="travis">Travis</p><p>Athougies</p></a>
          </h1>
        </div>
        <div id="gallery-modal" class="modal" style="display: hidden">
          <a href="#" id="gallery-prev"></a>
          <a href="#" id="gallery-next"></a>
          <img id="gallery-image" src="#" />
          <div id="gallery-caption">
            <span class="gallery-figure">Figure <span id="figure-number">0</span> &mdash;</span><span id="caption-text"></span>
          </div>
        </div>
        <div id="header">
            <h1 id="logo">
                <a href="../"><p class="travis">Travis</p><p>Athougies</p></a>
            </h1>
            <div id="taglines">
              technologist
              dreamer
              builder
            </div>
            <ul id="navigation">
              <li><h2>Navigation</h2>
                <ul>
                  <li><a href="../">Home</a></li>
                  <li><a href="../about.html">About</a></li>
                  <li><a href="../projects.html">Projects</a></li>
                  <li><a href="../contact.html">Contact</a></li>
                  <li><a href="../archive.html">Archive</a></li>
                </ul></li>
              <li><h2>Tags</h2>
                <ul>
                
                  <li><a href="../tags/haskell.html">haskell (16)</a></li>
                
                  <li><a href="../tags/hydroponics.html">hydroponics (9)</a></li>
                
                  <li><a href="../tags/sustainability.html">sustainability (5)</a></li>
                
                  <li><a href="../tags/gardening.html">gardening (4)</a></li>
                
                  <li><a href="../tags/math.html">math (3)</a></li>
                
                  <li><a href="../tags/beam.html">beam (3)</a></li>
                
                  <li><a href="../tags/web.html">web (2)</a></li>
                
                  <li><a href="../tags/type theory.html">type theory (1)</a></li>
                
                  <li><a href="../tags/physics.html">physics (1)</a></li>
                
                  <li><a href="../tags/hakyll.html">hakyll (1)</a></li>
                
                  <li><a href="../tags/food.html">food (1)</a></li>
                
                  <li><a href="../tags/finance.html">finance (1)</a></li>
                
                  <li><a href="../tags/databases.html">databases (1)</a></li>
                
                  <li><a href="../tags/business.html">business (1)</a></li>
                
                  <li><a href="../tags/agriculture.html">agriculture (1)</a></li>
                
                  <li><a href="../tags/HoTT.html">HoTT (1)</a></li>
                </ul></li>
            </ul>
          <div id="shamelessplug">
              Site proudly generated by
              <a href="http://jaspervdj.be/hakyll">Hakyll</a> <p></p>
              This site kept updated by <a href="http://travis-ci.org">Travis CI</a> <p></p>
              <img src="https://travis-ci.org/tathougies/travis-athougies-blog.svg?branch=master" />
          </div>
        </div>

        <div id="content">
            <h1>Mere Symbols</h1>

            <div class="info">
    Posted on <span class="date">May 24, 2024</span>
    
        by <span class="author">Travis Athougies</span>
    
</div>
<div class="tags">
  in
  <ul>
    
  </ul>
</div>



<div id="post">
<!-- -*- fill-column: 200 -*- -->
<p>The Vatican published a book on AI: <a href="https://jmt.scholasticahq.com/article/91230-encountering-artificial-intelligence-ethical-and-anthropological-investigations">Encountering Artificial Intelligence: Ethical and Anthropological
Investigations</a>. It’s a well laid out book, with good insights, as one
might expect from expert scholars and theologians.</p>
<p>What’s prompted the book, of course, is the meteoric rise of large language models (and probably diffusion-based generative audio-visual models like StableDiffusion), which have captured the public
imagination. As the book says, ChatGPT grew to more than a 100 million users in its first week of publication. That’s… a lot of people, so it’s no wonder the ethical implications behind AI have
captured the attention of many. AIs have already convinced couples to divorce and people to commit suicide. Clearly, someone needs to be talking about ethics at this point.</p>
<p>Naturally, this book approaches AI from a Catholic perspective, and in that sense, I think it achieves its goals. I’m going to share some of my notes and thoughts I have while going through the book,
but before I do that I want to start at the beginning.</p>
<h2 id="not-your-fathers-computing">Not Your Father’s Computing</h2>
<p>One of the first things the book does is define its terms. On page 18, the authors write:</p>
<blockquote>
<p>A computation is “the transformation of sequences of symbols according to precise rules.” This set of precise rules or “recipe for solving a specific problem by manipulating symbols” is called an algorithm.</p>
</blockquote>
<p>It then defines:</p>
<blockquote>
<p>Machine learning (ML) is a computational process and method of analysis by which algorithms make inferences and predictions based on input data</p>
</blockquote>
<p>They’re not <em>wrong</em>, but I’m not sure they’re <em>right</em> either. A lot of common discourse today talks about ‘algorithms’, these abstract ever-present entities of pure logic that run our lives. But what
is an algorithm really? I think the authors basically have it correct. An algorithm is a set of precise rules to solve a <em>specific</em> problem by manipulating <em>symbols</em>. In this way, algorithms are very
useful to us and predate computing. For example, multi-digit multiplication is a specific algorithm that we all know.</p>
<p>Now certainly, many machine learning problems, such as regressions and linear programming and some clustering methods, involve algorithms. However, I think the book fails to contend with the fact that
these algorithms are not what people talk about when we mean AI. None of these methods (or their related algorithmic cousins, expert systems) have been able to achieve anything close to ChatGPT.</p>
<p>Algorithms like the ones above can be analyzed, broken down, and understood. Modern AI is based, as the book identifies, on the notion of deep neural networks. Without going into too much technical
detail, essentially they take as input a large array of numbers and output another large array of numbers (thrilling, I know). What happens in between is pretty much a mystery.</p>
<p>Now when I say a ‘mystery’ I don’t mean that we don’t know what’s going on. Obviously, we do. Given that this is what I earn my living off of, I certainly know all the operations taking place in
minute detail (or at least my boss thinks I do!). What we don’t know is what any of the numbers <em>mean</em>. The numbers that govern the internal processing are derived not from any description of an
algorithm, but from a learning process. Again, the learning process is similarly a mystery. While we know every step of how to run the process, we don’t know really understand it. For example, the
graph below is the training loss of various BERT models. As loss decreases the model is perfoming better. Notice that at some points in training, the loss doesn’t move at all. We repeat the same
training process, but nothing changes, until finally, the loss drops drastically in a short period of time, almost as if the model ‘discovered’ something. Yet, ask any machine learning researcher what
this all means, and you’ll get blank stares or overconfident responses. No one knows. It’s not for lack of trying either; there have been many papers explaining various aspects <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, but there’s
no widespread consensus <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<figure>
<div class="figure"><a href="../images/ai-book/bert-graph.ppm"><img src="../images/ai-book/bert-graph.ppm" alt="BERT loss graphs. From &lt;em&gt;CoRe: An Efficient Coarse-refined Training Framework for BERT&lt;/em&gt; by Yang et al" width="auto"></a><p class="caption">BERT loss graphs. From <em>CoRe: An Efficient Coarse-refined Training Framework for BERT</em> by Yang et al</p></div>
<figcaption>BERT loss graphs. From <em>CoRe: An Efficient Coarse-refined Training Framework for BERT</em> by Yang et al</figcaption>
</figure>
<p>Essentially, while we understand what to do here, we don’t understand deeply why it works. This is a lot different than long multiplication for example. It’s trivial to explain that algorithm. It
relies on the distributed property of multiplication and the definition of place value. Every step is justifiable as to why it results in the correct answer. We’ve developed very good mechanisms
<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> to mechanically not only do multiplication but also to <em>prove</em> that following these steps will lead to the correct answer. Nothing similar exists for neural network models.</p>
<p>Many parents with kids who are bad sleepers have a bedtime routine. Sometimes, these routines are quite elaborate. My daughter, for example, demands I rub her feet, read her specific stories, and get
the lighting levels just right. Again, I understand every step of this process, but God help me if you ask me to explain why this works (if you know why this works, please tell me… my wife and I
would be thrilled). This is basically what we’re doing with AI, and we’ve discovered how to do it in the same way – it’s mostly trial and error with a few guiding principles.</p>
<h2 id="sir-this-is-a-wendys">Sir, this is a Wendy’s</h2>
<p>So if neural networks are not <em>algorithms</em> what are they? Well, again, I think we have to be careful with terms. Neural networks (or really, transformers, in the case of GPT) are algorithms. That means they are a sequence of well-defined steps to follow. However, the models that they run (meaning the weights learned during the learning process, combined with the algorithm to execute them) are not.</p>
<p>This may seem like a trivial distinction but it’s really not. In fact, it really matters. One of the biggest discoveries in mathematics and computer science is the sheer complexity that arises from
seemingly simple algorithms. One common thing I’ve witnessed in the current debates on AI is that many computer scientists are more willing to entertain the idea that consciousness and other seemingly
intractable problems are simply emergenty phenomenon, while others dismiss them outright as pure fantasy.</p>
<p>Personally, I believe that AI machines cannot have the same kind of agency as humans (I’ll get to this later), but I do think I fall into the camp of computer scientists who are absolutely willing to
entertain the notion that they might. The main source of this different approach I think comes down to one of the most shocking discoveries in computer science that any programmer or AI researcher
would be familiar with.</p>
<p>Okay, I’m going to go back into deep computer science here, so everyone hold on tight.</p>
<p>Imagine a grid of cells. Each cell is either <em>dead</em> or <em>alive</em>. Each cell has eight neighbors. I’m going to give the following rules to update the cell:</p>
<ol type="1">
<li>If a cell is dead, and the cell has three live neighbors, then make the cell alive in the next round (<em>birth rule</em>).</li>
<li>If a cell is alive, and has 0 or 1 neighbors, then it dies. Similarly, if it is alive and has more than 4 neighbors, it dies (<em>death rule</em>).</li>
<li>If a cell is alive and has 2 or 3 live neighbors, then it stays alive (<em>survival rule</em>).</li>
</ol>
<p>Easy right? We can understand this completely. If I give you a piece of graph paper with some cells filled in to signal they’re alive and some blank to show they’re dead, you can apply these rules for
as long as I ask, and give me the result. In fact, we can program computers to do this <a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<p>Okay so the truly great thing about these three rules, is that they fully encapsulate every possible computation that mankind can do. You can arrange alive or dead cells to do almost anything like
calculate pi <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, make a computer <a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>, or even simulate itself <a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. <em>Every single program</em> can be encoded into a pattern of live and dead cells.</p>
<p>This system is called Conway’s Game of Life. And here’s the thing, while we fully understand how to run Conway’s Game of Life (just follow the rules above), we actually can’t say a whole lot about
it. There are useful patterns, like the ones above, and then there are some which we really can’t say anything about. They may do something, they may not. It’s not only unknown what they do, it’s
<em>unknowable</em> and maybe even <em>indescribable</em> <a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>.</p>
<p>We understand the <em>meta-algorithm</em> completely, but we cannot understand the behavior with just any input.</p>
<p>Okay, computer science over.</p>
<p>This is really similar to AI. We understand the rules of the network (the <em>algorithm</em>) completely. For GPT, it’s a deep transformer decoder-only model with multi-headed softmax-attention, an embedding
step and a linear projection into the final domain (phew!). Given a description like this, I can easily write a program that does the computation step. However, this is not ChatGPT. ChatGPT is this
<em>plus</em> the weights trained by OpenAI. And, when you do the computation (the algorithm) with the weights, you get something that seems much more advanced than a long sequence of additions,
multiplications, exponentiations, and divisions. Like… a lot more advanced.</p>
<p>Given what we know about the Game of Life, that this process <em>could</em> result in something more is not one I could dismiss outright. Simply understanding the steps does not necessarily give us any
insight into the overall large problem.</p>
<h2 id="a-bunch-of-rocks-xkcd">A bunch of rocks <a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></h2>
<p>Ultimately, there is an insiduous category mistake in simply discussing AI in terms of algorithms. There are algorithms underpinning AI (the model structure), but this algorithm is not what people talk
about when they say AI. When someone talks about a computer do they mean the physical box or the physical box plus the software that runs it? It’s the same with AI. AI is the model plus the
weights. The model is an algorithm. The model and weights are capable of doing something else, but it’s not clear what the weights used for GPT et al are doing.</p>
<p>Quick thought experiment to drive this point home: What happens when the weights to a GPT-like model are all zero? The output is… zero, no matter the inputs. Again, understanding the algorithm does
not mean we know what the weights are doing.</p>
<p>I am not saying that this <em>proves</em> that AI models are anything special. I’m just pointing out that simply being an algorithm does not mean the system lacks transcendent complexity. I drew the analogy
to Conway’s game of life because I think it’s important to realize that even simple algorithms can, when put together, produce results that defy the abilities of human cognition. Just because
something is algorithmic does not make it characterizable. While Conway’s Game of Life is deterministic (it’s never subject to random chance), it is actually not determinable. Something being
algorithmic does not make it understandable.</p>
<h2 id="mere-symbols">Mere symbols</h2>
<p>This is an important point. On page 59, the authors say:</p>
<blockquote>
<p>Definitions of reason and intelligence commonly applied to AI abandon this interiority in favor of a twofold reduction. First, rationality and understanding become the logical manipulation of
symbolically represented information; and second, intelligence becomes efficacious problem-solving</p>
</blockquote>
<p>Given the path laid out above, it’s apparent that there is nothing reductive about symbolic manipulation. As we’ve seen, manipulation of symbols, while simple, provably can lead to things which
transcend human understanding. It’s truly the purview of God Himself.</p>
<p>Given that, it’s not at all obvious why it would at all be bad if intelligence were to be ‘merely’ efficacious problem-solving through the manipulation of symbols. That’s honestly enough to create
almost infinite complexity.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p><a href="https://proceedings.mlr.press/v202/li23p.html"><em>How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding</em>, Li, Yuchen and Li, Yuanzhi and Risteski, Andrej,Proceedings of the 40th International Conference on Machine Learning</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://proceedings.mlr.press/v202/von-oswald23a.html"><em>Transformers Learn In-Context by Gradient Descent</em>, Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan,Proceedings of Machine Learning Research</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>For example, <a href="https://arxiv.org/abs/2310.08540"><em>Revisiting the Hypothesis: Do pretrained Transformers Learn In-Context by Gradient Descent?</em></a> completely disagrees with the above.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>For example, see theorem provers like <a href="https://coq.inria.fr/">Coq</a>, <a href="https://leanprover-community.github.io/">Lean</a>, or <a href="https://wiki.portal.chalmers.se/agda/pmwiki.php">Agda</a>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>See here for an <a href="https://conwaylife.com/">online version</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><a href="https://www.youtube.com/watch?v=CeWMScRP_9s">Calculate Pi using Game of Life</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p><a href="https://www.youtube.com/watch?v=8unMqSp0bFY">Programmable computer in Game of Life</a><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><a href="https://oimo.io/works/life/">… it goes on forever …</a><a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>I cannot stress how truly unknowable this is. It is not simply difficult, or time-consuming, there are statements about various configurations that we <em>can never</em> know for
certain. This is the <a href="https://en.wikipedia.org/wiki/Halting_Problem">halting problem.</a>.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p><a href="https://xkcd.com/505/">A bunch of rocks</a><a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</div>

<div id="disqus_thread"></div>
<script type="text/javascript">
/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = 'travisathougiessblog'; // required: replace example with your forum shortname

/* * * DON'T EDIT BELOW THIS LINE * * */
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

        </div>
        <!-- Google Analytics Tracking -->
        <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-55204994-1', 'auto');
        ga('send', 'pageview');

        </script>
    </body>
</html>
